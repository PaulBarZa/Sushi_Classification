{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import seaborn\n",
    "import joblib\n",
    "from utils import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid tensorflow warnings and info messages about my poor bad CPU\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deep learning part**\n",
    "\n",
    "Note: See [here](https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory) for dataset directory structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path and names\n",
    "X_training_set_path = \"training_set/X_training.npy\"\n",
    "y_training_set_path = \"training_set/y_training.npy\"\n",
    "X_validation_set_path = \"validation_set/X_validation.npy\"\n",
    "y_validation_set_path = \"validation_set/y_validation.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model & data parameters\n",
    "model_name = 'retrain_mobilenet_v4'\n",
    "retrain_convolution = False\n",
    "num_classes = 50\n",
    "\n",
    "image_size = 192 #in pixels\n",
    "num_classes = 50\n",
    "validation_size = 0.2\n",
    "input_shape = (image_size, image_size, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "optimizer = keras.optimizers.Adam(1e-4) #learning_rate=0.001 (default value)\n",
    "epochs = 50\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load data from dataset images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset and normalize data to the range [-1, 1]\n",
    "X, y = load_data((image_size, image_size))\n",
    "X /= 127.5\n",
    "X -= 1\n",
    "# Split Training/Testing and validation test\n",
    "X, X_validation, y, y_validation = train_test_split(X, y, test_size=validation_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save dataset for next time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(training_set_path):\n",
    "    os.makedirs(training_set_path)\n",
    "    \n",
    "if not os.path.exists(validation_set_path):\n",
    "    os.makedirs(validation_set_path)\n",
    "    \n",
    "np.save(X_training_set_path, X)\n",
    "np.save(y_training_set_path, y)\n",
    "np.save(X_validation_set_path, X_validation)\n",
    "np.save(y_validation_set_path, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load data from already saved numpy array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(X_training_set_path)\n",
    "y = np.load(y_training_set_path)\n",
    "X_validation = np.load(X_validation_set_path)\n",
    "y_validation = np.load(y_validation_set_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call back\n",
    "#early_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    #featurewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    #width_shift_range=0.2,\n",
    "    #height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2)\n",
    "\n",
    "datagen.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileNet\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "\n",
    "pretrain = MobileNetV2(weights=\"imagenet\",  alpha=0.5, input_shape = input_shape, include_top = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ResNet\n",
    "from tensorflow.keras.applications.resnet import ResNet101\n",
    "\n",
    "pretrain = ResNet101(weights=\"imagenet\", input_shape = input_shape, include_top = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DenseNet\n",
    "from tensorflow.keras.applications.densenet import DenseNet201\n",
    "\n",
    "pretrain = DenseNet201(weights=\"imagenet\", input_shape = input_shape, include_top = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Network\n",
    "\n",
    "M = keras.Sequential()\n",
    "\n",
    "M.add(layers.Conv2D(32, (3, 3), input_shape = input_shape, activation = 'relu'))\n",
    "M.add(layers.MaxPooling2D(pool_size = (2, 2)))\n",
    "M.add(layers.Conv2D(32, (3, 3), activation = 'relu'))\n",
    "M.add(layers.MaxPooling2D(pool_size = (2, 2)))\n",
    "M.add(layers.Flatten())\n",
    "\n",
    "M.add(layers.Dense(64, activation = 'relu'))\n",
    "M.add(layers.Dense(num_classes, activation = 'softmax'))\n",
    "model = M\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init the selected model (if not a custom one, else do not run this part)\n",
    "if not retrain_convolution:\n",
    "    for layer in pretrain.layers:\n",
    "        layer.trainable = False\n",
    "    pretrain.layers[0].trainable = False\n",
    "    \n",
    "pretrain_out = pretrain.output\n",
    "\n",
    "M = layers.MaxPooling2D()(pretrain_out)\n",
    "M = layers.Flatten()(M)\n",
    "M = layers.Dropout(0.5)(M)\n",
    "M = layers.Dense(num_classes, activation=\"softmax\")(M)\n",
    "\n",
    "#Compile the model\n",
    "model = keras.Model(inputs=pretrain.input, outputs=M)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model without tensorflow data augmentation\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\", \"top_k_categorical_accuracy\"])\n",
    "history = model.fit(X, y, batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model with tensorflow data augmentation\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\", \"top_k_categorical_accuracy\"])\n",
    "history = model.fit(\n",
    "         datagen.flow(X, y, batch_size=batch_size, subset='training'),\n",
    "         validation_data=datagen.flow(X, y,batch_size=16, subset='validation'),\n",
    "         epochs=epochs, \n",
    "         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation of the model\n",
    "scores = model.evaluate(X_validation, y_validation, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict validation set\n",
    "prediction = np.argmax(model.predict(X_validation), axis=-1)\n",
    "y_prediction = np.argmax(y_validation, axis=-1)\n",
    "\n",
    "# Confusion matrix of this validation\n",
    "cm = metrics.confusion_matrix(y_prediction, prediction)\n",
    "plt.figure(figsize = (10,7))\n",
    "seaborn.heatmap(cm, annot=True, linewidths=1)\n",
    "plt.savefig(\"dl_confusion_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title(\"Retrain \" + model_name + \" (alpha= 0.5) top 1 accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Train\", \"Validation\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation top 5 values\n",
    "plt.plot(history.history['top_k_categorical_accuracy'])\n",
    "plt.plot(history.history['val_top_k_categorical_accuracy'])\n",
    "plt.title(\"Retrain \" + model_name + \" (alpha= 0.5) top 5 accuracy\")\n",
    "plt.ylabel(\"Top 5 categorical accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Train\", \"Validation\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"Retrain \" + model_name + \" (alpha= 0.5) loss\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Train\", \"Validation\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_path = './models/' + model_name + '.keras'\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set features extractor for Extremely Randomized Trees (ET) and Support Vector Machine (SVM)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path and names\n",
    "dl_model_name = \"retrain_mobilenet_v4\"\n",
    "\n",
    "# Layers to remove from our deep learning model to only get convolutif part\n",
    "layers_to_remove = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the deep learning model\n",
    "model = keras.models.load_model('./models/' + dl_model_name + '.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of the CNN (without the dense part)\n",
    "feature_extractor = keras.Model(model.input, model.layers[-layers_to_remove].output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extremely Randomized Trees & Support Vector Machine model** <br>\n",
    "This part is for add a model after our convolution\n",
    "\n",
    "- 1. We train our model on the same training set\n",
    "- 2. Test accuracy on the same validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "analyzer_path = \"./analyzer_model.joblib\"\n",
    "n_estimators = 225\n",
    "\n",
    "def transform_one_hot_labels(one_hot_labels):\n",
    "    y = []\n",
    "    for o in one_hot_labels:\n",
    "        y.append(np.argmax(o))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "**1. Training part**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training set\n",
    "X = np.load(X_training_set_path)\n",
    "y = np.load(y_training_set_path)\n",
    "\n",
    "# Labels need to be indice of the classes as target value, not one hot encoded\n",
    "y = transform_one_hot_labels(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extremely Randomized Trees**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init Extra trees mdoel\n",
    "model = ExtraTreesClassifier(n_estimators = n_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support Vector Machines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init the SVM model\n",
    "model = SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract features and train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features\n",
    "X = feature_extractor.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(n_estimators=225)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./random_forest.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the random forest model\n",
    "joblib.dump(model, analyzer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Validation part**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the validation set\n",
    "X_validation = np.load(X_validation_set_path)\n",
    "y_validation = np.load(y_validation_set_path)\n",
    "\n",
    "# Labels need to be indice of the classes as target value, not one hot encoded\n",
    "y_validation = transform_one_hot_labels(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the analyzer model (if needed)\n",
    "model = joblib.load(analyzer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on validation test\n",
    "X_validation_features = feature_extractor(X_validation)\n",
    "predicted_values = model.predict(X_validation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "print(\"Top 1 accuracy: \", metrics.accuracy_score(y_validation, predicted_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = metrics.confusion_matrix(y_validation_encoded, predicted_values)\n",
    "seaborn.heatmap(cm, annot=True, linewidths=1)\n",
    "plt.savefig(\"DL&AnalyzerModel_confusion_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
