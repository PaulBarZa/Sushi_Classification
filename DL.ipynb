{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import seaborn\n",
    "import joblib\n",
    "from utils import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid tensorflow warnings and info messages about my poor bad CPU\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path and names\n",
    "\n",
    "# Loaded dataset folders\n",
    "training_set_path = \"sets/training_set/\"\n",
    "validation_set_path = \"sets/validation_set/\"\n",
    "extracted_training_set_path = \"sets/extracted_training_set/\"\n",
    "extracted_validation_set_path = \"sets/extracted_validation_set/\"\n",
    "\n",
    "# Loaded dataset files\n",
    "X_training_set_path = training_set_path + \"X_training.npy\"\n",
    "y_training_set_path = training_set_path + \"y_training.npy\"\n",
    "X_validation_set_path = validation_set_path + \"X_validation.npy\"\n",
    "y_validation_set_path = validation_set_path + \"y_validation.npy\"\n",
    "X_extracted_training_set_path = extracted_training_set_path + \"X_extracted_training.npy\"\n",
    "X_extracted_validation_set_path = extracted_validation_set_path + \"X_extracted_validation.npy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deep learning part**\n",
    "\n",
    "Note: See [here](https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory) for dataset directory structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model & data parameters\n",
    "model_name = 'retrain_mobilenet'\n",
    "retrain_convolution = True\n",
    "\n",
    "image_size = 192 #in pixels\n",
    "num_classes = 50\n",
    "validation_size = 0.2\n",
    "input_shape = (image_size, image_size, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "optimizer = keras.optimizers.Adam(1e-4) #learning_rate=0.001 (default value)\n",
    "epochs = 50\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load data from dataset images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset and normalize data to the range [-1, 1]\n",
    "X, y = load_data((image_size, image_size))\n",
    "X /= 127.5\n",
    "X -= 1\n",
    "# Split Training/Testing and validation test\n",
    "X, X_validation, y, y_validation = train_test_split(X, y, test_size=validation_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load data from already saved numpy array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(X_training_set_path)\n",
    "y = np.load(y_training_set_path)\n",
    "X_validation = np.load(X_validation_set_path)\n",
    "y_validation = np.load(y_validation_set_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save dataset for next time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(training_set_path):\n",
    "    os.makedirs(training_set_path)\n",
    "    \n",
    "if not os.path.exists(validation_set_path):\n",
    "    os.makedirs(validation_set_path)\n",
    "    \n",
    "np.save(X_training_set_path, X)\n",
    "np.save(y_training_set_path, y)\n",
    "np.save(X_validation_set_path, X_validation)\n",
    "np.save(y_validation_set_path, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call back\n",
    "#early_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    #featurewise_center=True,\n",
    "    #featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2)\n",
    "\n",
    "datagen.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select a model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileNet\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "\n",
    "pretrain = MobileNetV2(weights=\"imagenet\", alpha=0.5, input_shape = input_shape, include_top = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not retrain_convolution:\n",
    "    for layer in pretrain.layers:\n",
    "        layer.trainable = False\n",
    "    pretrain.layers[0].trainable = False\n",
    "    \n",
    "pretrain_out = pretrain.output\n",
    "\n",
    "M = layers.MaxPooling2D()(pretrain_out)\n",
    "M = layers.Flatten()(M)\n",
    "M = layers.Dense(num_classes, activation=\"softmax\")(M)\n",
    "\n",
    "#Compile the model\n",
    "model = keras.Model(inputs=pretrain.input, outputs=M)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model without tensorflow data augmentation\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\", \"top_k_categorical_accuracy\"])\n",
    "history = model.fit(X, y, batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model with tensorflow data augmentation\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\", \"top_k_categorical_accuracy\"])\n",
    "history = model.fit(\n",
    "         datagen.flow(X, y, batch_size=batch_size, subset='training'),\n",
    "         validation_data=datagen.flow(X, y,batch_size=16, subset='validation'),\n",
    "         epochs=epochs, \n",
    "         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation of the model\n",
    "scores = model.evaluate(X_validation, y_validation, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict validation set\n",
    "prediction = np.argmax(model.predict(X_validation), axis=-1)\n",
    "y_prediction = np.argmax(y_validation, axis=-1)\n",
    "\n",
    "# Confusion matrix of this validation\n",
    "cm = metrics.confusion_matrix(y_prediction, prediction)\n",
    "plt.figure(figsize = (10,7))\n",
    "seaborn.heatmap(cm, annot=True, linewidths=1)\n",
    "plt.savefig(\"dl_confusion_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title(\"Retrain \" + model_name + \" top 1 accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Train\", \"Validation\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation top 5 values\n",
    "plt.plot(history.history['top_k_categorical_accuracy'])\n",
    "plt.plot(history.history['val_top_k_categorical_accuracy'])\n",
    "plt.title(\"Retrain \" + model_name + \" top 5 accuracy\")\n",
    "plt.ylabel(\"Top 5 categorical accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Train\", \"Validation\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"Retrain \" + model_name + \" loss\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Train\", \"Validation\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_path = './models/' + model_name + '.keras'\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set features extractor for Extremely Randomized Trees (ET) and Support Vector Machine (SVM)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path and names\n",
    "model_name = 'retrain_mobilenet'\n",
    "dl_model_name = model_name\n",
    "\n",
    "# Layers to remove from our deep learning model to only get convolutif part\n",
    "layers_to_remove = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the deep learning model\n",
    "model = keras.models.load_model('./models/' + dl_model_name + '.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of the CNN (without the dense part)\n",
    "feature_extractor = keras.Model(model.input, model.layers[-layers_to_remove].output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extremely Randomized Trees & Support Vector Machine model** <br>\n",
    "This part is for add a model after our convolution\n",
    "\n",
    "- 1. We train our model on the same training set\n",
    "- 2. Test accuracy on the same validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "et_analyzer_path = \"./et_analyzer_model.joblib\"\n",
    "svc_analyzer_path = \"./svc_analyzer_model.joblib\"\n",
    "n_estimators = 300\n",
    "\n",
    "def transform_one_hot_labels(one_hot_labels):\n",
    "    y = []\n",
    "    for o in one_hot_labels:\n",
    "        y.append(np.argmax(o))\n",
    "    return y\n",
    "\n",
    "def print_accuracy(predicted_prob, y_validation):\n",
    "    predicted_classes = []\n",
    "    for p in predicted_prob:\n",
    "        predicted_classes.append(np.argmax(p))\n",
    "\n",
    "    print(\"Top 1 accuracy: \", metrics.accuracy_score(y_validation, predicted_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "**1. Training part**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training set\n",
    "X = np.load(X_training_set_path)\n",
    "y = np.load(y_training_set_path)\n",
    "\n",
    "# Labels need to be indice of the classes as target value, not one hot encoded\n",
    "y = transform_one_hot_labels(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract training features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features\n",
    "X = feature_extractor.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load extracted training features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(X_extracted_training_set_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save extracted training features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(extracted_training_set_path):\n",
    "    os.makedirs(extracted_training_set_path)\n",
    "    \n",
    "np.save(X_extracted_training_set_path, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extremely Randomized Trees**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init Extra trees mdoel\n",
    "et_model = ExtraTreesClassifier(n_estimators = n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "et_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the extra trees model\n",
    "joblib.dump(et_model, et_analyzer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support Vector Machines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init the SVM model\n",
    "svc_model = SVC(probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "svc_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the random forest model\n",
    "joblib.dump(svc_model, svc_analyzer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Validation part**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the validation set\n",
    "X_validation = np.load(X_validation_set_path)\n",
    "y_validation = np.load(y_validation_set_path)\n",
    "\n",
    "# Labels need to be indice of the classes as target value, not one hot encoded\n",
    "y_validation = transform_one_hot_labels(y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load a model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra trees model\n",
    "model = joblib.load(et_analyzer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Svc model\n",
    "model = joblib.load(svc_analyzer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract validation features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features\n",
    "X_validation_features = feature_extractor.predict(X_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load extracted validation features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validation_features = np.load(X_extracted_validation_set_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save extracted validation features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(extracted_validation_set_path):\n",
    "    os.makedirs(extracted_validation_set_path)\n",
    "\n",
    "np.save(X_extracted_validation_set_path, X_validation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on validation test\n",
    "predicted_prob = model.predict_proba(X_validation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "print_accuracy(predicted_prob, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combine Extra Trees and Support Vector Classifier prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validation_features = np.load(X_extracted_validation_set_path)\n",
    "y_validation = np.load(y_validation_set_path)\n",
    "\n",
    "# Labels need to be indice of the classes as target value, not one hot encoded\n",
    "y_validation = transform_one_hot_labels(y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra trees model & prediction\n",
    "et_model = joblib.load(et_analyzer_path)\n",
    "et_predicted_prob = et_model.predict_proba(X_validation_features)\n",
    "\n",
    "# Svc model & prediction\n",
    "svc_model = joblib.load(svc_analyzer_path)\n",
    "svc_predicted_prob = svc_model.predict_proba(X_validation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_prob = (et_predicted_prob + svc_predicted_prob) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "print_accuracy(predicted_prob, y_validation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}